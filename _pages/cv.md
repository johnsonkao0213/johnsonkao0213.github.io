---
layout: archive
title: "CV"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

[Download full CV here](../files/cv.pdf)

Education
======
* M.S. in Computer Science, University of California, Los Angeles, advised by Prof. [Cho-Jui Hsieh](https://web.cs.ucla.edu/~chohsieh/index.html)
* B.S. in Computer Science, National Yang Ming Chiao Tung University (previous National Chiao Tung University)

Work Experience
======
## **Himax Imaging**
### *AI engineer Intern*
  * Investigated research and employed model compression techniques such as structural pruning and quantization to a unified face detection, head pose estimation, and face emotion recognition model on Himax AI chips running on Windows notebook, speeding up 20% of FPS and 3x times fewer FLOPs.

## **Appier**
### *Machine Learning Scientist*
  * Improved User Lookalike models to produce the distinguished user score for each unique user id based on existing client site activities and deployed models online by using CI/CD pipelines, enhancing 20% improvement on AUROC compared to baseline.
  * Extracted user behavior patterns from 1000K+ conversion funnel data and analyzed the Click-Through Rate of different campaigns using PySpark, SQL and Pandas, resulting in 120% revenue growth within 3 months.
  * Decreased the uncertainty for outlier and lose bidding data in bidding models, saving up 30% of the trouble shooting time.

## **Cinnamon AI**
### *AI Bootcamp Summer Intern*
  * Implemented a Seq2Seq-based model to recommend tourist attractions based on personal interest and arrange suitable trip routes deployed on Gradio to make a fast user interface.

Research Experience
======
* University of California, Los Angeles, Research Assistant
  * Supervisor: Prof. [Cho-Jui Hsieh](https://web.cs.ucla.edu/~chohsieh/index.html)
  * Proposed an auto-prompting approach that combines LLMs and external symbolic solver to solve Algebra Word Problem by utilizing different prompting strategies, achieving 10% improvement in answer accuracy on both English and Chinese datasets.
  * Curated a new and larger algebraic dataset with prompt optimization which contains multiple variables questions to evaluate our proposed reasoning approaches on solving more challengeable Algebra Word Problem.

* Stanford University with National Yang Ming Chiao Tung University, Research Assistant
  * Supervisor: Prof. [Yung-Ju, Chang](https://www.armuro.info/) & [Stanford Screenomics Lab](https://screenomics.stanford.edu/)
  * Investigated the use of Vision Language Models (VLMs), particularly GPT-4V, in the analysis of smartphone user activities from screenshots, offering an alternative to traditional app usage data analysis limitations, providing highly convinced reliability score compared to human coders.
  * Conducted a two-week user study via users’ self-reported experience as evidence to support "killing-time" periods are opportune for user engagement with notifications that demand user attention and engagement.

* Institute of Information Science Academia Sinica, Research Assistant
  * Supervisor: Prof. [Keh-Yi, Su](https://homepage.iis.sinica.edu.tw/pages/kysu/index_en.html)
  * Utilized deep learning methods and conducted experiments to Knowledge-Guided Algebra Word Problem Solver, achieving better equation accuracy and problem accuracy on English algebraic datasets.
  * Designed and built a two-stage neural model, which adopts the concepts of the solving strategies by humans, generating multiple expression trees explicitly and representing the reasonable solving process behind the model’s solution equation.

* National Yang Ming Chiao Tung University, Research Assistant
  * Supervisor: Prof. [Yung-Ju, Chang](https://www.armuro.info/) & Prof. [Wei-Chen Chiu](https://walonchiu.github.io/)
  * Leveraged deep learning fusion model to investigate users’ kill time behavior based on 1000K+ mobile phone-sensor and screenshot data, which is collected by our developed Android App.
  * Employed a two-stage clustering approach to separate users into four groups according to the patterns of their phone-usage behaviors, and then built a fusion model for each group, yielding overall strong performance on AUROC.

* National Yang Ming Chiao Tung University, Research Student
  * Supervisor: Prof. [Ching-Chun Huang](http://acm.cs.nctu.edu.tw/)
  * Applied model compression using structural pruning and knowledge distillation on YOLOv4. The developed models not only fit for embedded systems (Ex: Jetson TX2) but also achieve higher FPS and mAP at the same time on the multi-spectral infrared dataset.
  * Winner of the award: “2021 ACM ICMR Embedded Deep Learning Object Detection Model Compression Competition for Traffic in Asian Countries” -- Final Round.

Skills
======
* Programming: C/C++, Python (Package: PyTorch, Tensorflow, PySpark, HuggingFace), SQL, Shell Script, HTML, CSS, MATLAB, Verilog
* DevOps & Tools: GCP, Docker, Kubernetes, Git, Jenkins, CI/CD, Airflow, System and Network Administration, Grafana, LATEX

Publications
======
* Kuei-Chun Kao, Ruochen Wang, Cho-Jui Hsieh “Can MLLMs really learn implicit task vectors and knowledge under multimodal in-context learning?” 2024
* Kuei-Chun Kao, Ethan Hsu, Ruochen Wang, Cho-Jui Hsieh “Enhancing Multi-Image Understanding in MLLMs through Question-Aware Image Captioning” 2024
* Kuei-Chun Kao, Ruochen Wang, Cho-Jui Hsieh “Solving for X and Beyond: Can Large Language Models Solve Complex Math Problems with More-Than-Two Unknowns?”, EMNLP'24
* Yung-Ju Chang*, Yu-Chun Chen*, Kuei-Chun Kao*, Yu-Jen Lee*, Mu-Jung Cho, Yikun Chi, Thomas N. Robinson, Byron Reeves, Nilam Ram “When Killing-Time Periods Don't Boost Notification Engagement: Insights from a Multimodal Large Language Model Analysis of Smartphone Screen Activity”, CHI'25(preprint, * indicates equal contribution)
* Yu-Chun Chen*, Kuei-Chun Kao*, Yu-Jen Lee*, Yung-Ju Chang “Does Receiving Less Personally Relevant but Attention-demanding Notifications while ‘Killing Time’ Increase Engagement? An Exploratory Study”, CHI'25 (preprint, * indicates equal contribution)
* Kuei-Chun Kao, Chao-Chun Liang, Keh-Yih Su “Knowledge-Guided Algebra Word Problem Solving”, 2023 (preprint)
*	Yu-Chun Chen, Yu-Jen Lee, Kuei-Chun Kao, Jie Tsai, En-Chi Liang, Wei-Chen Chiu, Faye Shih, Yung-Ju Chang “Are You Killing Time? Predicting Smartphone Users’ Time-killing Moments via Fusion of Smartphone Sensor Data and Screenshots”, CHI'23 
*	Yu-Chun Chen*, Kuei-Chun Kao*, Yu-Jen Lee, Faye Shih, Wei-Chen Chiu, Yung-Ju Chang “Killing-Time Detection from Smartphone Screenshots”, UbiComp'21 (* indicates equal contribution)

  
Teaching
======
* Introduce to Natural Language Preprocessing (2022 Spring)
  * Lecturer: [An-Zi Yen](https://azyen0522.github.io/)
  
Service and leadership
======
* CHI 2024 reviewer
* Ubicomp 2022 reviewer
* CS Student Union (academic affair)

Honors
======
* Scholarship for Academic Excellence performance 2 times (1% of computer science department per semester)
* NYCU GPE programming exam Ranked 1% (out of 200 students of NYCU)
* Best People's Choice Award - Poster in Taiwan Association of Computer Human Interaction (TAICHI'21)
* NTU-IBM Q System 2020 Q-Camp, Best Presentation Award, Sep. 2020
